{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MatterTunerConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ManualSplitDataModuleConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">num_workers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">pin_memory</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">train</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OMAT24DatasetConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'omat24'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">src</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/mnt/datasets/salex/val'</span><span style=\"font-weight: bold\">))</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">validation</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ORBBackboneConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">reset_backbone</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">freeze_backbone</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">reset_output_heads</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">use_pretrained_normalizers</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">properties</span>=<span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EnergyPropertyConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'energy'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'float'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MAELossConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mae'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">reduction</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">loss_coefficient</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'energy'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ForcesPropertyConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'forces'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'float'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MAELossConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mae'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">reduction</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">loss_coefficient</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'forces'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">conservative</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StressesPropertyConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stresses'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'float'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MAELossConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mae'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">reduction</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span><span style=\"font-weight: bold\">)</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">loss_coefficient</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stresses'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">conservative</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">optimizer</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AdamWConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">per_parameter_hparams</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'AdamW'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0001</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-08</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">betas</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.999</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">weight_decay</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">amsgrad</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">lr_scheduler</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ignore_gpu_batch_transform_error</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">normalizers</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'orb'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">pretrained_model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'orb-v2'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">system</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ORBSystemConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">radius</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_num_neighbors</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">trainer</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TrainerConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">accelerator</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">strategy</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">num_nodes</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">devices</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">precision</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'32-true'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">deterministic</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">max_epochs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">min_epochs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">max_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">min_steps</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">max_time</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">val_check_interval</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">check_val_every_n_epoch</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">log_every_n_steps</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">gradient_clip_val</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">gradient_clip_algorithm</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">checkpoint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">early_stopping</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ema</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">loggers</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">additional_trainer_kwargs</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'fast_dev_run'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'accelerator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">recipes</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMatterTunerConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdata\u001b[0m=\u001b[1;35mManualSplitDataModuleConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mbatch_size\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "        \u001b[33mnum_workers\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
       "        \u001b[33mpin_memory\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[33mtrain\u001b[0m=\u001b[1;35mOMAT24DatasetConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'omat24'\u001b[0m, \u001b[33msrc\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/mnt/datasets/salex/val'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mvalidation\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[1;35mORBBackboneConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mreset_backbone\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mfreeze_backbone\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mreset_output_heads\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[33muse_pretrained_normalizers\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[33mproperties\u001b[0m=\u001b[1m[\u001b[0m\n",
       "            \u001b[1;35mEnergyPropertyConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'energy'\u001b[0m,\n",
       "                \u001b[33mdtype\u001b[0m=\u001b[32m'float'\u001b[0m,\n",
       "                \u001b[33mloss\u001b[0m=\u001b[1;35mMAELossConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'mae'\u001b[0m, \u001b[33mreduction\u001b[0m=\u001b[32m'mean'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mloss_coefficient\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                \u001b[33mtype\u001b[0m=\u001b[32m'energy'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mForcesPropertyConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'forces'\u001b[0m,\n",
       "                \u001b[33mdtype\u001b[0m=\u001b[32m'float'\u001b[0m,\n",
       "                \u001b[33mloss\u001b[0m=\u001b[1;35mMAELossConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'mae'\u001b[0m, \u001b[33mreduction\u001b[0m=\u001b[32m'mean'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mloss_coefficient\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                \u001b[33mtype\u001b[0m=\u001b[32m'forces'\u001b[0m,\n",
       "                \u001b[33mconservative\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[1;35mStressesPropertyConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mname\u001b[0m=\u001b[32m'stresses'\u001b[0m,\n",
       "                \u001b[33mdtype\u001b[0m=\u001b[32m'float'\u001b[0m,\n",
       "                \u001b[33mloss\u001b[0m=\u001b[1;35mMAELossConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'mae'\u001b[0m, \u001b[33mreduction\u001b[0m=\u001b[32m'mean'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "                \u001b[33mloss_coefficient\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
       "                \u001b[33mtype\u001b[0m=\u001b[32m'stresses'\u001b[0m,\n",
       "                \u001b[33mconservative\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[33moptimizer\u001b[0m=\u001b[1;35mAdamWConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mper_parameter_hparams\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'AdamW'\u001b[0m,\n",
       "            \u001b[33mlr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0001\u001b[0m,\n",
       "            \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-08\u001b[0m,\n",
       "            \u001b[33mbetas\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m, \u001b[1;36m0.999\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.01\u001b[0m,\n",
       "            \u001b[33mamsgrad\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mlr_scheduler\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mignore_gpu_batch_transform_error\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[33mnormalizers\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'orb'\u001b[0m,\n",
       "        \u001b[33mpretrained_model\u001b[0m=\u001b[32m'orb-v2'\u001b[0m,\n",
       "        \u001b[33msystem\u001b[0m=\u001b[1;35mORBSystemConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mradius\u001b[0m=\u001b[1;36m6\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33mmax_num_neighbors\u001b[0m=\u001b[1;36m120\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mtrainer\u001b[0m=\u001b[1;35mTrainerConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33maccelerator\u001b[0m=\u001b[32m'auto'\u001b[0m,\n",
       "        \u001b[33mstrategy\u001b[0m=\u001b[32m'auto'\u001b[0m,\n",
       "        \u001b[33mnum_nodes\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "        \u001b[33mdevices\u001b[0m=\u001b[32m'auto'\u001b[0m,\n",
       "        \u001b[33mprecision\u001b[0m=\u001b[32m'32-true'\u001b[0m,\n",
       "        \u001b[33mdeterministic\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mmax_epochs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mmin_epochs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mmax_steps\u001b[0m=\u001b[1;36m-1\u001b[0m,\n",
       "        \u001b[33mmin_steps\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mmax_time\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mval_check_interval\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mcheck_val_every_n_epoch\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "        \u001b[33mlog_every_n_steps\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mgradient_clip_val\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mgradient_clip_algorithm\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mcheckpoint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mearly_stopping\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mema\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mloggers\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
       "        \u001b[33madditional_trainer_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'fast_dev_run'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'accelerator'\u001b[0m: \u001b[32m'cpu'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mrecipes\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/orb_models/utils.py:30: UserWarning: Setting global torch default dtype to torch.float32.\n",
      "  warnings.warn(f\"Setting global torch default dtype to {torch_dtype}.\")\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The `fairchem` package is not installed. Please install it by running `pip install fairchem`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/MatterTune/src/mattertune/util.py:9\u001b[0m, in \u001b[0;36moptional_import_error_message\u001b[0;34m(pip_package_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/data/omat24.py:34\u001b[0m, in \u001b[0;36mOMAT24Dataset.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional_import_error_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfairchem\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfairchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AseDBDataset  \u001b[38;5;66;03m# type: ignore[reportMissingImports] # noqa\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m AseDBDataset(config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msrc)})\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fairchem'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hparams\n\u001b[1;32m     46\u001b[0m hp \u001b[38;5;241m=\u001b[39m hparams()\n\u001b[0;32m---> 47\u001b[0m tune_output \u001b[38;5;241m=\u001b[39m \u001b[43mMatterTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m model, trainer \u001b[38;5;241m=\u001b[39m tune_output\u001b[38;5;241m.\u001b[39mmodel, tune_output\u001b[38;5;241m.\u001b[39mtrainer\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/main.py:278\u001b[0m, in \u001b[0;36mMatterTuner.tune\u001b[0;34m(self, trainer_kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Create the trainer\u001b[39;00m\n\u001b[1;32m    277\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrainer_kwargs_)\n\u001b[0;32m--> 278\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Return the trained model\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TuneOutput(model\u001b[38;5;241m=\u001b[39mlightning_module, trainer\u001b[38;5;241m=\u001b[39mtrainer)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:974\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    971\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[0;32m--> 974\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_setup_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001b[39;00m\n\u001b[1;32m    975\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: configuring model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    976\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_configure_model(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:107\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m    104\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_setup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mdatamodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m _call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n\u001b[1;32m    109\u001b[0m _call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:198\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 198\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/data/datamodule.py:206\u001b[0m, in \u001b[0;36mMatterTuneDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msetup(stage)\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# PyTorch Lightning checks for the *existence* of the\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# `train_dataloader`, `val_dataloader`, `test_dataloader`,\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# and `predict_dataloader` methods to determine which dataloaders\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Instead, we will check, here, what datasets are available, and\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# remove the corresponding methods if the dataset is not available.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     METHOD_NAME_MAPPING \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m     }\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/data/datamodule.py:93\u001b[0m, in \u001b[0;36mManualSplitDataModuleConfig.create_datasets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_datasets\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     92\u001b[0m     datasets: DatasetMapping \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 93\u001b[0m     datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (val \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m         datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m val\u001b[38;5;241m.\u001b[39mcreate_dataset()\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/data/omat24.py:25\u001b[0m, in \u001b[0;36mOMAT24DatasetConfig.create_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOMAT24Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/data/omat24.py:33\u001b[0m, in \u001b[0;36mOMAT24Dataset.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m optional_import_error_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfairchem\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfairchem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AseDBDataset  \u001b[38;5;66;03m# type: ignore[reportMissingImports] # noqa\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m AseDBDataset(config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msrc)})\n",
      "File \u001b[0;32m/net/csefiles/coc-fung-cluster/lingyu/miniconda3/envs/orbv3-tune/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/MatterTune/src/mattertune/util.py:11\u001b[0m, in \u001b[0;36moptional_import_error_message\u001b[0;34m(pip_package_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpip_package_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` package is not installed. Please install it by running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpip_package_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: The `fairchem` package is not installed. Please install it by running `pip install fairchem`."
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import rich\n",
    "\n",
    "import mattertune.configs as MC\n",
    "from mattertune import MatterTuner\n",
    "\n",
    "\n",
    "def hparams():\n",
    "    hparams = MC.MatterTunerConfig.draft()\n",
    "\n",
    "    # Model hparams\n",
    "    hparams.model = MC.ORBBackboneConfig.draft()\n",
    "    hparams.model.pretrained_model = \"orb-v2\"\n",
    "    hparams.model.ignore_gpu_batch_transform_error = True\n",
    "    hparams.model.optimizer = MC.AdamWConfig(lr=1.0e-4)\n",
    "\n",
    "    hparams.model.properties = []\n",
    "    energy = MC.EnergyPropertyConfig(loss=MC.MAELossConfig())\n",
    "    hparams.model.properties.append(energy)\n",
    "    forces = MC.ForcesPropertyConfig(loss=MC.MAELossConfig(), conservative=False)\n",
    "    hparams.model.properties.append(forces)\n",
    "    stresses = MC.StressesPropertyConfig(loss=MC.MAELossConfig(), conservative=False)\n",
    "    hparams.model.properties.append(stresses)\n",
    "\n",
    "    # Data hparams\n",
    "    hparams.data = MC.ManualSplitDataModuleConfig.draft()\n",
    "    hparams.data.train = MC.OMAT24DatasetConfig.draft()\n",
    "    hparams.data.train.src = Path(\"/mnt/datasets/salex/val/\")\n",
    "    hparams.data.batch_size = 1\n",
    "    hparams.data.num_workers = 8\n",
    "\n",
    "    # Trainer hparams\n",
    "    hparams.trainer.additional_trainer_kwargs = {\n",
    "        \"fast_dev_run\": True,\n",
    "        # \"devices\": [0],\n",
    "        \"accelerator\": \"cpu\",\n",
    "    }\n",
    "\n",
    "    hparams = hparams.finalize()\n",
    "    rich.print(hparams)\n",
    "    return hparams\n",
    "\n",
    "\n",
    "hp = hparams()\n",
    "tune_output = MatterTuner(hp).tune()\n",
    "model, trainer = tune_output.model, tune_output.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mattertune.wrappers.potential.MatterTunePotential object at 0x77fe147c05d0>\n",
      "<mattertune.wrappers.ase_calculator.MatterTuneCalculator object at 0x77fdf9135790>\n"
     ]
    }
   ],
   "source": [
    "property_predictor = model.property_predictor()\n",
    "print(property_predictor)\n",
    "\n",
    "calculator = model.ase_calculator()\n",
    "print(calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='H2O', pbc=True, cell=[10.0, 10.0, 10.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jmp-peft/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cbe33f4b014d898ab7abe001024213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'energy': tensor[1, 1] [[0.044]], 'forces': tensor[3, 3] n=9 x[-0.183, 0.094] =1.242e-09 =0.084 [[-0.056, 0.028, 0.089], [0.016, -0.021, 0.094], [0.040, -0.008, -0.183]], 'stresses': tensor[1, 3, 3] n=9 x[-0.135, 0.108] =-0.055 =0.090 [[[-0.085, 0.037, -0.135], [0.037, 0.108, -0.105], [-0.135, -0.105, -0.107]]]}]\n"
     ]
    }
   ],
   "source": [
    "import ase\n",
    "\n",
    "# Create a test periodic system\n",
    "atoms = ase.Atoms(\n",
    "    \"H2O\", positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]], cell=[10, 10, 10], pbc=True\n",
    ")\n",
    "print(atoms)\n",
    "\n",
    "print(property_predictor.predict([atoms], model.hparams.properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: False\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atoms(symbols='H2O', pbc=True, cell=[10.0, 10.0, 10.0])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc0727c229d4571b5574c2bd9c16db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06458454579114914\n"
     ]
    }
   ],
   "source": [
    "import ase\n",
    "\n",
    "# Create a test periodic system\n",
    "atoms = ase.Atoms(\n",
    "    \"H2O\", positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]], cell=[10, 10, 10], pbc=True\n",
    ")\n",
    "print(atoms)\n",
    "\n",
    "# Set the calculator\n",
    "atoms.calc = calculator\n",
    "\n",
    "# Calculate the energy\n",
    "energy = atoms.get_potential_energy()\n",
    "print(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:fsspec.local:open file: /workspaces/MatterTune/examples/lightning_logs/version_22/hparams.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44e5b101b9b40e3aa3327f32ac73791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ase.Atoms 1 energy: tensor[1, 1] [[-0.065]]\n",
      "ase.Atoms 1 forces: tensor[3, 3] n=9 x[-0.167, 0.117] =8.278e-10 =0.089 [[-0.067, 0.050, -0.167], [-0.016, 0.017, 0.117], [0.083, -0.068, 0.050]]\n",
      "ase.Atoms 2 energy: tensor[1, 1] [[-0.065]]\n",
      "ase.Atoms 2 forces: tensor[3, 3] n=9 x[-0.167, 0.117] =8.278e-10 =0.089 [[-0.067, 0.050, -0.167], [-0.016, 0.017, 0.117], [0.083, -0.068, 0.050]]\n"
     ]
    }
   ],
   "source": [
    "property_predictor = model.property_predictor()\n",
    "atoms_1 = ase.Atoms(\n",
    "    \"H2O\", positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]], cell=[10, 10, 10], pbc=True\n",
    ")\n",
    "atoms_2 = ase.Atoms(\n",
    "    \"H2O\", positions=[[0, 0, 0], [0, 0, 1], [0, 1, 0]], cell=[10, 10, 10], pbc=True\n",
    ")\n",
    "atoms = [atoms_1, atoms_2]\n",
    "predictions = property_predictor.predict(atoms, [\"energy\", \"forces\"])\n",
    "print(\"ase.Atoms 1 energy:\", predictions[0][\"energy\"])\n",
    "print(\"ase.Atoms 1 forces:\", predictions[0][\"forces\"])\n",
    "print(\"ase.Atoms 2 energy:\", predictions[1][\"energy\"])\n",
    "print(\"ase.Atoms 2 forces:\", predictions[1][\"forces\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jmp-peft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
